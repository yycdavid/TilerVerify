{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Quickstart\n",
    "\n",
    "This notebook demonstrates how you can find adversarial examples for a pre-trained example network on the MNIST dataset.\n",
    "\n",
    "We suggest having the `Gurobi` solver installed, since its performance is significantly faster. If this is not possible, the `Cbc` solver is another option.\n",
    "\n",
    "The `Images` package is only necessary for visualizing the MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "using MIPVerify\n",
    "using Gurobi\n",
    "using Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup\n",
    "\n",
    "### MNIST dataset\n",
    "\n",
    "We begin by loading the MNIST dataset. The data is provided as a Julia `struct` for easy access. The training images and test images are provided as a 4-dimensional array of size `(num_samples, height, width, num_channels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnist:\n",
       "  `train`: {LabelledImageDataset}\n",
       "    `images`: 60000 images of size (28, 28, 1), with pixels in [0.0, 1.0].\n",
       "    `labels`: 60000 corresponding labels, with 10 unique labels in [0, 9].\n",
       "  `test`: {LabelledImageDataset}\n",
       "    `images`: 10000 images of size (28, 28, 1), with pixels in [0.0, 1.0].\n",
       "    `labels`: 10000 corresponding labels, with 10 unique labels in [0, 9]."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = MIPVerify.read_datasets(\"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{LabelledImageDataset}\n",
       "    `images`: 60000 images of size (28, 28, 1), with pixels in [0.0, 1.0].\n",
       "    `labels`: 60000 corresponding labels, with 10 unique labels in [0, 9]."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(mnist.train.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can use `Images.colorview` to preview these images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000-element Array{UInt8,1}:\n",
       " 0x05\n",
       " 0x00\n",
       " 0x04\n",
       " 0x01\n",
       " 0x09\n",
       " 0x02\n",
       " 0x01\n",
       " 0x03\n",
       " 0x01\n",
       " 0x04\n",
       " 0x03\n",
       " 0x05\n",
       " 0x03\n",
       "    ⋮\n",
       " 0x07\n",
       " 0x08\n",
       " 0x09\n",
       " 0x02\n",
       " 0x09\n",
       " 0x05\n",
       " 0x01\n",
       " 0x08\n",
       " 0x03\n",
       " 0x05\n",
       " 0x06\n",
       " 0x08"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sample Neural Network\n",
    "\n",
    "We import a sample pre-trained neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential net MNIST.n1\n",
       "  (1) Flatten(): flattens 4 dimensional input, with dimensions permuted according to the order [4, 3, 2, 1]\n",
       "  (2) Linear(784 -> 40)\n",
       "  (3) ReLU()\n",
       "  (4) Linear(40 -> 20)\n",
       "  (5) ReLU()\n",
       "  (6) Linear(20 -> 10)\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = MIPVerify.get_example_network_params(\"MNIST.n1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "`MIPVerify.frac_correct` allows us to verify that the network has a reasonable accuracy on the test set of 96.95%. (This step is crucial when working with your own neural net parameters; since the training is done outside of Julia, a common mistake is to transfer the parameters incorrectly.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mComputing fraction correct...100%|██████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9695"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIPVerify.frac_correct(n1, mnist.test, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We feed the first image into the neural net, obtaining the activations of the final softmax layer. \n",
    "\n",
    "Note that the image must be specified as a 4-dimensional array with size `(1, height, width, num_channels)`. We provide a helper function `MIPVerify.get_image` that extracts the image from the dataset while preserving all four dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×28×28×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 26, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[:, :, 27, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[:, :, 28, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image = MIPVerify.get_image(mnist.test.images, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float64,1}:\n",
       " -0.0207439\n",
       " -0.0174995\n",
       "  0.167072 \n",
       " -0.0532371\n",
       " -0.019291 \n",
       " -0.0795155\n",
       "  0.0619113\n",
       "  4.83397  \n",
       "  0.46706  \n",
       "  0.401452 "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_activations = sample_image |> n1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The category that has the largest activation is category 8, corresponding to a label of 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output_activations |> MIPVerify.get_max_index) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This matches the true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIPVerify.get_label(mnist.test.labels, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Finding an Adversarial Example\n",
    "\n",
    "We now try to find an adversarial example for the first image on `n1`, setting the target category as index `10` (corresponding to a true label of 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[notice | MIPVerify]: Attempting to find adversarial example. Neural net predicted label is 8, target labels are [10]\n",
      "\u001b[39m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 10 entries:\n",
       "  :PerturbationFamily => unrestricted\n",
       "  :TargetIndexes      => [10]\n",
       "  :SolveStatus        => :Optimal\n",
       "  :TotalTime          => 45.7059\n",
       "  :TighteningApproach => \"loaded_from_cache\"\n",
       "  :Output             => JuMP.GenericAffExpr{Float64,JuMP.Variable}[-0.01206386…\n",
       "  :PredictedIndex     => 8\n",
       "  :Model              => Minimization problem with:…\n",
       "  :Perturbation       => JuMP.Variable[__anon__ __anon__ __anon__ __anon__ __an…\n",
       "  :PerturbedInput     => JuMP.Variable[__anon__ __anon__ __anon__ __anon__ __an…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[notice | MIPVerify]: Loading model from cache.\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "target_label_index = 10\n",
    "d = MIPVerify.find_adversarial_example(n1, sample_image, target_label_index, GurobiSolver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 3385 rows, 3256 columns and 71132 nonzeros\r\n",
      "Variable types: 3196 continuous, 60 integer (60 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [2e-05, 7e+02]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+02]\r\n",
      "  RHS range        [4e-03, 7e+02]\r\n",
      "\r\n",
      "MIP start did not produce a new incumbent solution\r\n",
      "MIP start violates constraint R1024 by 1.000000000\r\n",
      "\r\n",
      "Presolve removed 2956 rows and 2227 columns\r\n",
      "Presolve time: 0.24s\r\n",
      "Presolved: 429 rows, 1029 columns, 61365 nonzeros\r\n",
      "Variable types: 969 continuous, 60 integer (60 binary)\r\n",
      "\r\n",
      "Root relaxation: objective 0.000000e+00, 223 iterations, 0.02 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.00000    0    4          -    0.00000      -     -    0s\r\n",
      "Another try with MIP start\r\n",
      "H    0     0                      36.9304736    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    4   36.93047    0.00000   100%     -    0s\r\n",
      "H    0     0                      32.4680084    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    5   32.46801    0.00000   100%     -    0s\r\n",
      "     0     2    0.00000    0    5   32.46801    0.00000   100%     -    0s\r\n",
      "H  158    66                       6.5385430    0.00000   100%  75.0    1s\r\n",
      "*  211    89              39       6.0319390    0.00000   100%  72.6    1s\r\n",
      "   810   396    0.00000   30    5    6.03194    0.00000   100%  55.1    5s\r\n",
      "  1999   499    5.45511   20   18    6.03194    0.00000   100%  54.5   10s\r\n",
      "* 3637   867              45       6.0194767    0.26700  95.6%  50.8   14s\r\n",
      "  3916   915     cutoff   29         6.01948    0.33754  94.4%  50.5   15s\r\n",
      "  6299  1426    5.10373   32    8    6.01948    0.79458  86.8%  47.4   20s\r\n",
      "* 7684  1418              47       5.5203782    1.34055  75.7%  45.2   22s\r\n",
      "  8667  1483    4.82718   28    7    5.52038    1.72176  68.8%  44.1   25s\r\n",
      " 10878  1549    4.87282   28    9    5.52038    2.53334  54.1%  43.2   30s\r\n",
      "*12267  1104              45       4.6601251    2.94232  36.9%  42.9   33s\r\n",
      "*12643  1016              44       4.6418593    3.08461  33.5%  42.5   34s\r\n",
      " 12886   924     cutoff   24         4.64186    3.25833  29.8%  42.3   35s\r\n",
      " 14885   224     cutoff   33         4.64186    4.28405  7.71%  41.2   40s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Gomory: 1\r\n",
      "  Projected implied bound: 1\r\n",
      "  Flow cover: 4\r\n",
      "\r\n",
      "Explored 15220 nodes (620612 simplex iterations) in 41.40 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 8: 4.64186 4.66013 5.52038 ... 36.9305\r\n",
      "\r\n",
      "Optimal solution found (tolerance 1.00e-04)\r\n",
      "Best objective 4.641859316319e+00, best bound 4.641859316319e+00, gap 0.0000%\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1×28×28×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 26, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[:, :, 27, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[:, :, 28, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using JuMP\n",
    "\n",
    "perturbed_sample_image = getvalue(d[:PerturbedInput])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As a sanity check, we feed the perturbed image into the neural net and inspect the activation in the final layer. We verify that the perturbed image does maximize the activation of the target label index, which is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float64,1}:\n",
       "  1.05198 \n",
       "  0.785344\n",
       "  0.313807\n",
       "  0.427011\n",
       "  0.369729\n",
       "  0.256145\n",
       "  0.66623 \n",
       "  4.56707 \n",
       " -0.147984\n",
       "  4.56707 "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbed_sample_image |> n1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We visualize the perturbed image and compare it to the original image. Since we are minimizing the L1-norm, changes are made to only a few pixels, but the magnitude of these changes are large (and noticeable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAJiS0dEAP+Hj8y/AAAB1klEQVRo3u3Zu2sUURzF8Y8mKQQbDQoWPioLLSSIICSCj0ZjYWH+haRRy4B/glhaWNjbCEIgIiIoRHwVaSS+MRYqIghaqJBCiMWMsJHsuuOE3Ts/72nm7swwX86cPZd7GbKysvqtdVVuPo8LNYHre+0wPjCr+erYwwcYXWNg/FrkHmZl/YdqO5dOYBIfsYSr+IQ3NYHxp7aeA9tm+Ba7/jj3Dc/+8sAPuIj5VBzGBw62uzCJfXiOPRjBYRzEe2xvufcnPmNb+fudnGEPtaKHyzovVDcpspzHgZbzS3iNF9iMs7icisP4wEp7/E46jWt4iiP4korD+MA1yXArFsrjBK6n5DA+cLD+IziDLfiKV6k5jA+s3cNR3MWQYs1zLzWH8YG1eziuyO8OHq1yfQpX+ukwPrBWDzfgPvbiKB6m6DA+sFYPpxV7jVu6y2+5Hw7jA/+5hycxgx84YfV59Lda953xX2kzejiMSxjATZ3zY+UfJf4rTb+HA3iM/VjE8fKYrMP4wMoZ7sbLcnwKs6k7jA+sNJfuxO1yPI0bTXAYH1gpwynsKMdzirVK8g7jA7vO8BDONdFhfGDXGY5hYzlexPemOIwPrLy3eIJj2n9bSs5hfGBW8/ULlPE/E/nN6ocAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 Array{Gray{Float64},2}:\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " ⋮                                       ⋱                    \n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(1.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorview(Gray, perturbed_sample_image[1, :, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAJiS0dEAP+Hj8y/AAABq0lEQVRo3u3ZP2vVUByH8U+9dRBcrCg4WDs5dCkigqCC4mLboYN9C9dFO3Z2d3TwHXQRBEERESrooA5dRO0/vB1URBDqoIWihTokQylcvWlKe/LjfJec/CEPD19OkkPIycnJycnJycnJycmpn75uJybRxlesYwbf8LEm8MBeG8YHdu1wBUPbjv3Eh//c8AvuYC4Vw/jA/m4n2hjBPIZxBpdxHp9xcsu1G/iOE+X+J7nDPUxflYuPKLqcw7ktx9exjAUM4BbupWIYH1ipw3/lOu7jPa5gNRXD+MBd6fA43pXbSTxIyTA+sL/+LbiJY/iBpdQM4wNrz8MLeI6Dim+el6kZxgfWnodjiv5m8TpFw/jAWh0ewjX8xm38SdEwPrBWh9OKtcZTvErVMD5wx+/DcTzEGkb19hzdF8P4wB3Nw6O4ixae6L2/fTGMD6w8D1t4g7PoKN6HnZQN4wMrd3gai+V4Ao9SN4wPrPQsPYVn5Xgaj5tgGB9YqcMbGCzHL7DZBMP4wJ47vISpJhrGB/bc4UUcLscd/GqKYXxg5bXFW1zV/d9ScobxgTnNz1/6vTnNezs1ygAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 Array{Gray{Float64},2}:\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " ⋮                                       ⋱                    \n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorview(Gray, sample_image[1, :, :, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "That concludes this quickstart! The next tutorial will introduce you to each of the layers, and show how you can import your own neural network parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.4",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
